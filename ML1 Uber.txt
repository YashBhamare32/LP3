# imports
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib as mpl
import random as rd

df=pd.read_csv("uber.csv")

df

df.hist()

df.corr

df.dtypes

df1=df

df1.describe()

df1.columns

df1.fare_amount

df1.fare_amount.describe()

# Checking Correlation in DataFrame for individual features
# According to assumption in regression model, inputs fields must not have more inter correlations.
# ield with least correlation with output can be droped.
corr=df1.corr
corr

print(df1.columns)

print(df1.head())

df1.columns = df1.columns.str.strip()

import pandas as pd
import numpy as np

# Example of using IQR to detect outliers
Q1 = df1['fare_amount'].quantile(0.25)
Q3 = df1['fare_amount'].quantile(0.75)
IQR = Q3 - Q1
outliers = df1[(df1['fare_amount'] < (Q1 - 1.5 * IQR)) | (df1['fare_amount'] > (Q3 + 1.5 * IQR))]
print(df1.dtypes)

df1['pickup_datetime'] = pd.to_datetime(df1['pickup_datetime'])

numeric_df = df1.select_dtypes(include=[np.number])
corr_matrix = numeric_df.corr()

sns.heatmap(corr_matrix, annot=True, fmt=".2f")

print(df1.isna().sum())

# Remove rows with NaNs:
df1 = df1.dropna()

# Inpute missing values: You can fill NaNs with a specific value (like the mean or median).
#df1.fillna(df1.mean(), inplace=True)

print(df1.dtypes)

# imports for model
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler


# Define input features and target variable
x = df1[['passenger_count']]
y = df1['fare_amount']

# Initialize the scaler
scaler = MinMaxScaler()

# Scale the entire feature dataset
x_scaled = scaler.fit_transform(x)

# Split the scaled data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.25, random_state=20)

# Checking Dimensions of Data
# x_scaled = x_train + x_test (After Scaling followed by Spliting of DataFrame.)
print(x_scaled.shape)
print(x_train.shape)
print(x_test.shape)

# Creation of Linear Regression Model
from sklearn.linear_model import LinearRegression

# Instantiate LinearRegression Model
lr = LinearRegression()

# Fit method to train model 
lr.fit(x_train, y_train)

# Checking Differnt Attributes of Fitted Model
print(lr.predict(x_test))
print(lr.score(x_train, y_train))
print(lr.coef_)
print(lr.intercept_)

# Prediction on LinearRegression Model x_test -> y_test
y_pred = lr.predict(x_test)
y_pred

# Evaluation of Model(Evaluation Matrices)
from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score, adjusted_rand_score

# Evaluate the model
print("Scikit-Learn Model Evaluation:")
print(f"R-squared: {r2_score(y_test, y_pred):.4f}") # r2 value represents accuracy. 
print(f"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred):.4f}")
print(f"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred):.4f}")
print(f"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}")

# Import
from sklearn.ensemble import RandomForestRegressor

# Instantiation
rfr = RandomForestRegressor() 

# Fit RandomForest Model
rfr.fit(x_test, y_test)

# Prediction on RandomForest Model x_test -> y_test
y_pred = rfr.predict(x_test)
y_pred

# Evaluation of Model(Evaluation Matrices)
from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score, adjusted_rand_score

# Evaluate the model
print("Scikit-Learn Model Evaluation:")
print(f"R-squared: {r2_score(y_test, y_pred):.4f}") # r2 value represents accuracy. 
print(f"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred):.4f}")
print(f"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred):.4f}")
print(f"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}")

'''

# Cross-validation
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')
print(f"Cross-Validated MSE: {-cv_scores.mean():.2f}")

# Fit the model using statsmodels
X_train_sm = sm.add_constant(X_train)  # Add constant term for intercept
model_sm = sm.OLS(y_train, X_train_sm).fit()

# Summary of the statsmodels results
print("\nStatsmodels Regression Summary:")
print(model_sm.summary())
'''
